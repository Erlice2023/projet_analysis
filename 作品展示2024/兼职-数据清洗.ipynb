{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据清洗\n",
    "#量化\n",
    "#删除列\n",
    "#补空值\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "import joblib\n",
    "import heapq\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "connect = pymysql.connect(user=\"xxx\",  password=\"xxx\",  host=\"xxx\",  port=xxx,charset=\"xxx\")  \n",
    "conn = connect.cursor()  \n",
    "conn.execute(\"use test_spider\")\n",
    "conn.execute(\"SELECT COLUMN_NAME 列名,COLUMN_COMMENT 备注 FROM information_schema. COLUMNS WHERE TABLE_NAME = 'xxx'\") \n",
    "name_columns=conn.fetchall()\n",
    "name_columns_chinese=[]\n",
    "name_columns_english=[]\n",
    "for each in name_columns:\n",
    "    if each[1]=='':\n",
    "        name_columns_chinese.append(each[0])\n",
    "    else:\n",
    "        name_columns_chinese.append(each[1])\n",
    "    name_columns_english.append(each[0])\n",
    "sql=\"select * from xxx\"\n",
    "df_sz= pd.read_sql(sql,connect)\n",
    "s=dict(zip(name_columns_english,name_columns_chinese))\n",
    "df_sz.rename(columns=s,inplace=True)\n",
    "#列翻译完成\n",
    "conn.close()\n",
    "connect.commit()\n",
    "connect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新抖数据处理\n",
    "df_sz=df_sz['XXX'].str.contains(\"XXX\"))]\n",
    "df_sz=df_sz['XXX']>='XXX')&(df_sz['XXX']<='XXX')]###高亮时间筛选与去重\n",
    "df_sz.drop_duplicates(subset=['XXX'],inplace=True)\n",
    "#数据处理过程代码集合\n",
    "df_sz_clean=df_sz.copy()\n",
    "#城市按一二线与其他线分类处理完成 一线为3 三三线以后为1\n",
    "df_city_grade=pd.read_excel(r'xxx')\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : 3 if x in df_city_grade['XXX'].dropna().to_list() or\\\n",
    "x in df_city_grade['XXX'].dropna().to_list() else 2 if x in df_city_grade['XXX'].dropna().to_list() else 1)\n",
    "#类别按照关联类（体育, 健康，美食，时尚，科技）与非关联类处理完成 强关联为1 其余为0\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x in ['XXX'] else 0)\n",
    "#别按照独热防虚拟拆分\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x ==\"男\" else 0)\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x ==\"女\" else 0)\n",
    "df_sz_clean.drop(columns=['XXX'],inplace=True)\n",
    "#新抖标签处理  强关联 美妆护肤 运动健身 颜值达人 生活 为1 其余为0\n",
    "def function(a,b): \n",
    "    for each in bq_list:\n",
    "        if each in a:\n",
    "            return 1\n",
    "    return 0\n",
    "bq_list=['XXX']\n",
    "df_sz_clean['XXX']=df_sz_clean.apply(lambda x :function(x['XXX'],bq_list),axis=1)\n",
    "#mcn简介处理  有的为1 其余为0\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if len(x)>1 else 0)\n",
    "#省份处理\n",
    "df_province_grade=pd.read_excel(r'XXX')\n",
    "for each in ['XXX']:\n",
    "    df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x in df_province_grade['XXX'].dropna().to_list() else 0)\n",
    "#粉丝团处理\n",
    "def function_mid(a): \n",
    "    if a!='null':\n",
    "        return re.search('total_fans_count\": \"(.*?)\"',str(a)).group(1)\n",
    "    else:\n",
    "        return '未知'\n",
    "def function_mid2(a): \n",
    "    if a!='null':\n",
    "        return re.search('active_fans_count\": \"(.*?)\"',str(a)).group(1)\n",
    "    else:\n",
    "        return '未知'\n",
    "df_sz_clean['XXX']=df_sz_clean.apply(lambda x :function_mid(x['XXX']),axis=1)\n",
    "df_sz_clean['XXX']=df_sz_clean.apply(lambda x :function_mid2(x['XXX']),axis=1)\n",
    "cotent_list=['XXX']   #新统计标签\n",
    "def function_mid3(a): \n",
    "    for each in cotent_list:\n",
    "        if each in a:\n",
    "            return 1\n",
    "    return 0   \n",
    "df_sz_clean['XXX']=df_sz_clean.apply(lambda x :function_mid3(x['XXX']),axis=1)\n",
    "for each in ['XXX']:\n",
    "    if df_sz_clean['XXX'].str.contains(each)].shape['XXX']==0:\n",
    "        continue        \n",
    "    df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x.find(each)>-1 else 0)\n",
    "#新抖计算的账号标签处理  强关联为1 若关联为0\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x.find(\"运动健身\")>-1 else 0)\n",
    "#个人认证信息处理\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x:1 if len(x)>1 else 0)\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x :1 if x.find(\"健身\")>-1 or x.find(\"健身\")>-1 else 0)\n",
    "#粉丝数处理：\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : float(x['XXX'])*10000 if 'w' in str(x) else int(x))\n",
    "#种草比例处理：\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].str.replace(\"%\",\"\")\n",
    "#总获赞数处理：\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : float(x['XXX'])*10000 if 'w' in str(x) else float(x['XXX'])*100000000 if '亿' in str(x) else int(x))\n",
    "#内容词云处理 强关联内容词云为1 若关联为0\n",
    "cotent_word_list=cotent_word_list=['XXX']\n",
    "def function_mid4(a): \n",
    "    for each in cotent_word_list:\n",
    "        if each in a:\n",
    "            return 1\n",
    "    return 0   \n",
    "df_sz_clean['XXX']=df_sz_clean.apply(lambda x :function_mid4(x['XXX']),axis=1)\n",
    "#功能使用-商品品类处理：强关联内容词云为1 若关联为0\n",
    "store_list=['XXX']\n",
    "def function_mid5(a): \n",
    "    for each in cotent_word_list:\n",
    "        if each in a:\n",
    "            return 1\n",
    "    return 0   \n",
    "df_sz_clean['XXX']=df_sz_clean.apply(lambda x :function_mid5(x['XXX']),axis=1)\n",
    "#带货比例处理\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].str.replace(\"%\",\"\")\n",
    "#企业认证信息处理：\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : 1 if len(x)>1 else 0)\n",
    "#全平台粉丝数处理\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : float(x['XXX'])*10000 if 'w' in str(x) else int(x))\n",
    "#火山粉丝数处理\n",
    "#头条粉丝数处理\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : float(x['XXX'])*10000 if 'w' in str(x) else int(x))\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : float(x['XXX'])*10000 if 'w' in str(x) else int(x))\n",
    "#删除无关列\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x:float(x['XXX'])/float(x['XXX']) if x.find(\":\")>-1 else x)\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].apply(lambda x : np.nan if x==\"\" else x)\n",
    "df_sz_clean['XXX']=df_sz_clean['XXX'].astype(float)  #男性占总数的比例\n",
    "df_sz_clean_finish=df_sz_clean.drop(columns=['XXX'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抖店后台数据处理\n",
    "end_day='xxx'  #数据结算日期\n",
    "df_live_record=pd.read_csv(r'xxx')   #退款这里有略微偏差 可能和数据的变动有关\n",
    "df_live_record['XXX']=pd.to_datetime(df_live_record['XXX'])\n",
    "df_live_record.rename(columns={'pay_gmv':'直播期间成交金额','refund_gmv':'直播期间订单退款金额'},inplace=True)\n",
    "df_live_record['XXX']=df_live_record['XXX'].apply(lambda x:str(x)['XXX']) \n",
    "df_live_record_now=df_live_record['XXX']>=\"XXX\"]  #当月直播记录\n",
    "live_count=df_live_record_now.groupby(\"uid\").count()['XXX']]           #将live_start作为直播次数的统计项\n",
    "live_count.reset_index(drop=False,inplace=True)\n",
    "live_count.rename(columns={\"live_start\":\"当月直播次数\"},inplace=True)\n",
    "df_live_record_now=pd.merge(df_live_record_now,live_count,on=\"uid\",how='left') #将每个主播当月的直播次数统计下来\n",
    "df_live_record_now_mid=df_live_record_now.copy()\n",
    "df_live_record_now_mid.drop_duplicates(subset=['XXX'],inplace=True)  #将每天直播多场的数据只保留一场\n",
    "live_time_now=df_live_record_now_mid.groupby(\"uid\").count()['XXX']]      #将live_start作为直播天数的统计项\n",
    "live_time_now.rename(columns={\"live_start\":\"当月直播天数\"},inplace=True)\n",
    "live_time_now.reset_index(drop=False,inplace=True)\n",
    "df_live_record_now=df_live_record_now['XXX']]\n",
    "df_live_record_now=pd.merge(df_live_record_now,live_time_now,on=\"uid\",how=\"left\")#当月直播天数匹配完毕\n",
    "df_live_record_now=pd.merge(df_live_record_now.groupby(\"uid\").sum().reset_index(drop=False)['XXX']],df_live_record_now.groupby(\"uid\").mean().reset_index(drop=False)['XXX']],on=\"uid\",how=\"left\")\n",
    "df_live_record_now['XXX']=df_live_record_now['XXX']-df_live_record_now['XXX']\n",
    "df_live_record_now.sort_values(by=['XXX'],ascending=False,inplace=True)\n",
    "df_live_record_now.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "score1=df_live_record_now['XXX']*0.15)]['XXX'].values['XXX']\n",
    "score1=1067\n",
    "df_live_record_now['XXX']=df_live_record_now['XXX'].apply(lambda x:1 if x>=score1 else 0)\n",
    "df_live_record_now['XXX']=df_live_record_now['XXX']\n",
    "df_live_record_now.to_excel(r'xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
